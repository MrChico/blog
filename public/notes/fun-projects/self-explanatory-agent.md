# Self Explanatory Agent

An agent mapping actions to words-phrases. can the same action be mapped to different
words dependent on the context? 

If you cant explained what an action is in a certain context, meaning what the hoped
outcome would be and why the action is performed, then perhaps you should not take an
action. Backchannel-sounds like "hmm" could be a way of describing that here the
uncertainties regarding what actions to take are large.


## Introduction
A babbling Agent playing a game. The end.

An agent playing a game, RL setup, but all actions are multi-modal. An action is a set of motor-skilled based (motoric- ?) actions and their spoken representation, their linguistic meaning, their semantical meaning. This could be useful for interoperability listen to the agent explain what it does in an temporal end-to-end fashion.


### Background
I walk around and talk to myself. Both unconsciously in a classic <strong>"lost in thought"</strong>  way and purposefully when I think and work out concepts. My thinking is closely condition on talking because I often use the generative linguistic(language) model but without the transformation to motoric signals in my mouth and throat. Speaking in my mind. I do this for reading as well (I think it is a non-optimal way of reading).


## Prerequisites
* Language
* RL policy for gameplay
* Voice (for interpretability)
  * How much of my thinking is conditioned on actual whole words. How much is conditioned on flow and intonation.
* Action and speech/word correlation
  * Dataset?
  * Define


Really it is the <strong>action-phrasing mapping</strong> which is all that is not known. Generate
sentences for actions, the inverse of action understanding/classification. AI complete,
analagous to NP-complete.
